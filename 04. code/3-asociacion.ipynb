{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"3-asociacion.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"machine_shape":"hm"}},"cells":[{"cell_type":"code","metadata":{"id":"0E0dUbzsgeLc"},"source":["#**********************************************************************************************\n","# @Name: Process for the association of the demand to the nearest segment\n","# @Author: Team 21\n","# @Date: 2020/09/16 18:40:47\n","# @Help: \n","#***********************************************************************************************\n","\n","#Libraries import ------------------------------------------------------------------------------\n","import datetime as dt                 # Date manipulation\n","import pandas as pd                   # Data manipulation\n","import numpy as np                    # Numeric manipulation\n","import os, glob                       # System management\n","import time                           # Time information\n","import re                             # Regular expressions\n","import pytz                           # Library to perform TimeZone related calculations\n","\n","#Development -----------------------------------------------------------------------------------"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t19vAOKcvVYS"},"source":["# As the data processing will be pretty expensive in computation terms,\n","# the process was made in the Google Colab workspace so the data is stored in Google Drive\n","# to process the data at a local level or using data from a different source,\n","# the rout must be changed\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u5R45XlCg-vg"},"source":["# Introduction --------------------------------------------------------------------------------\n","# Process for the association of the demand to the nearest segment\n","#\n","# According to the geographical location of the event and the configuration of the points of \n","# the transport network, we make the following process:\n","# \n","# 1. Build the association function to the nearest point using the haversine equation.\n","# 2. Identify the first node.\n","# 3. Filter the data of the nodes according to the identification of the first node and then \n","#    apply again the function of the nearest point.\n","\n","# function to the nearest point using the haversine equation ----------------------------------\n","def haversine(lon1, lat1, lon2, lat2):\n","  # lon1, lat1, lon2, lat2 are arrays  \n","  KM = 6378.1370   # mean equatorial radius\n","  lon1, lat1, lon2, lat2 = map(np.deg2rad, [lon1, lat1, lon2, lat2])\n","  dlat = lat2 - lat1 \n","  dlon = lon2 - lon1 \n","  a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n","  c = 2 * np.arcsin(np.sqrt(a)) \n","  # Returns the distance in kilometers for two pointss (lon1, lat1) y (lon2, lat2)\n","  return KM * c\n","\n","# function to identify very far points --------------------------------------------------------\n","def far_point(xcoord, ycoord, link_xcoord1, link_ycoord1, limit):\n","  # xcoord, ycoord, link_xcoord1, link_ycoord1 are arrays, the limit is the maximum distance allowed\n","  # returns True if the distance between an event and the closest node is superior to the limit \n","  return [np.amin(haversine(x, y, link_xcoord1, link_ycoord1)) > limit for x,y in zip(xcoord, ycoord)]\n","\n","# function to calculate the nearest link ------------------------------------------------------\n","def idx_nearest_link(xcoord, ycoord, link_xcoord1, link_ycoord1):\n","  # xcoord, ycoord, link_xcoord1, link_ycoord1 are arrays\n","  nearest = np.array([np.argmin(haversine(x, y, link_xcoord1, link_ycoord1)) for x,y in zip(xcoord, ycoord)])\n","  # en el codigo siguiente se utiliza el nombre del dataframe de 'links' y los nombres de sus columnas:\n","    # 'Inode' es el id del primer nodo del i-esimo link\n","    # 'LongitudJn' y 'LatitudJn' son las coordenadas geogr√°ficas del segundo nodo del i-esimo link\n","  link = nearest + np.array([np.argmin([haversine(xcoord[i], ycoord[i],\n","                                                  x, y) for x,y in links.loc[links['Inode'] == links.loc[node, 'Inode'],\n","                                                                             ['LongitudJn','LatitudJn']].values]) for i,node in list(enumerate(nearest))])\n","  # devuelve el id del dataset de links del link mas cercano\n","  return [links['Id'].values[index] for index in link]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lsAMEkq8umW3"},"source":["# Loop to get all files from folder -----------------------------------------------------------\n","\n","# Define dates for data processing\n","inicio = '20191101'\n","fin = '20200510'\n","\n","actuales = pd.date_range(start = inicio, end = fin).strftime(\"%Y%m%d\")\n","actuales = [int(x) for x in actuales]\n","\n","# Verifies the processed files and drop them from the list\n","procesados = glob.glob('/content/drive/My Drive/ds4a-project/outputs/*.csv')\n","procesados = [int(re.findall(r'\\d{8}', i)[0]) for i in procesados]\n","\n","to_run = [x for x in actuales if x not in procesados]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kgMR-159tEHV"},"source":["# Load of data --------------------------------------------------------------------------------\n","\n","# Path of files definition\n","path_data = \"/content/drive/My Drive/ds4a-project/inputs/transacciones/\"\n","path_to = \"/content/drive/My Drive/ds4a-project/outputs/\"\n","path_stats = \"/content/drive/My Drive/ds4a-project/stats/\"\n","\n","# Links data load\n","links = pd.read_csv('/content/drive/My Drive/ds4a-project/inputs/maestros/links_clean.csv')\n","\n","stats = []\n","\n","for i in to_run:\n","  startTime = time.time()\n","  \n","  print(\"Inicia Proceso: \" + str(i) + \" \" + str(dt.datetime.now(pytz.timezone('America/Bogota')).time()))\n","  \n","  data = pd.read_csv(path_data + str(i) + '.csv')\n","\n","  # Se crean las columnas aplicando las funciones definidas\n","  data['FAR'] = far_point(data['LONGITUD'].values, data['LATITUD'].values, links['LongitudIn'].values, links['LatitudIn'].values, limit = 1)\n","  print((time.time() - startTime))\n","  data['LINK'] = idx_nearest_link(data['LONGITUD'].values, data['LATITUD'].values, links['LongitudIn'].values, links['LatitudIn'].values)\n","\n","  executionTime = (time.time() - startTime)\n","\n","  print(executionTime)\n","\n","  # The transformed data are saved\n","  data.to_csv(path_to + str(i) + \".csv\")\n","\n","  # The process statistics are saved\n","  try:\n","    linksfar = data['FAR'].value_counts().iloc[1]\n","  except:\n","    linksfar = 0\n","  else:\n","    linksfar\n","  \n","  stats.append(\n","        {\n","          'Archivo': i,\n","          'Tiempo': executionTime,\n","          'LinksAsigandos' : data['FAR'].value_counts().iloc[0],\n","          'LinksFar' : linksfar\n","        }\n","    )\n","\n","stats = pd.DataFrame(stats)\n","stats.to_csv(path_stats + inicio + \"_\" + fin + \"_stats.csv\", index = False)"],"execution_count":null,"outputs":[]}]}